#Redis线上问题定位案例及解决思路

## 线上Redis的cpu利用率在凌晨出现突刺，达到90%+
定位思路：
cpu利用升高，说明其短时间内负载升高过快，那么可能的方向是

1、是否短期内访问redis流量过大    
    这部分要看是否外部请求流量爆涨，或者是否触发了某些死循环操作在持续访问redis，前者查询kibana就行，后者则需要排查业务代码了

2、是否有慢查询之类的耗时操作？    
    慢查询可以通过redis的log查询，

3、是否有某个key过大？

4、主库是否在做备份aof之类的操作？    
    如果是单独的实例，又该怎么分析？

如果想观察当时发生了什么，那么只能通过开通monitor观察这段时间的请求(长期开会影响性能)

以下为chatgpt的答案
- 检查redis实例是否存在大量的高并发请求，可以通过命令行工具如top或者htop来查看当前redis进程的CPU占用情况，并观察是否有大量的用户请求导致CPU利用率暴涨。
- 检查redis配置文件中的maxclients参数，该参数指定了redis同时处理连接的最大数量。如果该值过小，可能会导致连接数达到上限并导致CPU利用率上升。可以通过修改配置文件中的maxclients参数来增加redis的并发连接数。
- 检查redis实例是否被频繁地进行持久化操作，如RDB快照或者AOF日志写入。这些操作会导致redis在执行期间占用大量的CPU资源。可以通过查看redis日志文件以及相关配置来确认是否有持久化操作导致CPU利用率上升。
- 检查机器的负载情况，包括内存使用率和磁盘IO等。如果机器的负载过高，可能会导致redis无法正常处理请求，并且可能会导致CPU利用率上升。可以通过命令行工具如top或者htop来查看机器的负载情况。
- 检查redis是否存在长时间的阻塞操作，比如慢查询或者阻塞的Lua脚本。这些操作会导致redis在执行期间长时间占用CPU资源。可以通过redis的monitor命令来查看当前正在执行的命令，并检查是否存在长时间阻塞的操作。
- 检查redis实例是否存在内存碎片化问题，如果redis实例分配的内存无法满足请求的需求，则可能会导致频繁的内存分配和回收，从而导致CPU利用率上升。可以通过redis-cli工具的info命令来查看redis实例的内存使用情况。
- 检查redis版本是否存在已知的性能问题或者bug，如果是，请及时升级到最新版本，以修复可能存在的性能问题。
- 如果以上排查方案都没有发现问题，可以考虑使用性能分析工具，如perf或者oprofile等，来进行深入的性能分析，以定位CPU利用率暴涨的具体原因。





