《并发》
服务器如何处理并发？
单机如何处理高并发？百万？
为什么基于事件驱动的服务器能实现高并发？
基于事件驱动的服务器，无需为每一个请求创建额外的对应线程，虽然可以省去创建线程与销毁线程的开销，但它在处理网络请求时，会把侦听到的请求放在事件队列中交给观察者，事件循环会不停的处理这些网络请求。

在事件循环中，每一次循环都会查看是否有事件待处理，如果有的话就取出来执行。

那在它执行当前循环的网络请求时，其他网络请求是不是就处于等待状态？这跟单线程有什么区别？还是说它会额外的开一个线程去处理请求以及执行相关回调？如果是这样的话，那它不就跟每线程/每请求的模式是一样的了么？
表示迷惑。。。。




这种并发实际说的是并发的不活跃的长连接，并不是并发请求典型的后端服务，在逻辑上可以划分为两层，跟业务无关的通信层，负责socket连接的创建和管理，负责bind/listen/accept/send/recv...通信层上面是业务逻辑层，负责被动响应请求，或主动推送业务消息通信层特点：都是IO行为，几乎不大消耗CPU连接数很多，可能同时有10K甚至100K个TCP连接通信协议就那么几种，decode/encode简单外部网络是慢速IO，收发一点数据可能要1秒甚至更久业务逻辑层特点：少量CPU消耗，大部分时间在等待数据库或者其它网络服务返回业务逻辑五花八门，逻辑中往往需要调用别的网络服务，如db并发请求数，往往小于连接数，10K个连接，可能每秒只有100个请求单个业务请求通常很快，毫秒级别，几十毫秒算慢的了如果完全采用传统的多线程模型，1个tcp连接对应1个线程，10K个连接需要10K个线程，典型的内存消耗是10G。但是业务逻辑层并发请求往往要小1到2个数量级，每个请求往往只需要100ms以内，所以业务逻辑层需要的线程数，比通信层小2-3个数量级，不需要10K个线程，只要100个甚至10个就够了。这种2-3个数量级差距的不匹配，促使了第一代事件驱动的流行，常见的模型，纷纷把通信层剥离出来，用事件驱动的形式取代多线程，但是在业务逻辑层仍然采用多线程模型。几个著名的例子:nginx负责通信层，PHP-FPM负责业务逻辑层nginx负责通信层，uwsgi负责Python的业务逻辑层tomcat nio负责通信层，业务逻辑层扔到线程池里处理这些模型都很成功，用几百个甚至区区几十个线程/进程，满足了几万甚至几十万的并发连接。在整个199X年到2010年，这个模型都相当的适用，之后移动互联网兴起，随之也出现越来越多的网络API服务，我们的业务逻辑层，不但要跟内网的网络服务通信，还要跟外网的服务通信，在业务逻辑层也产生了大量的外网网络IO，导致一个请求不能在100ms内完成，可能增加到了500ms甚至几秒钟，其中大部分时间是在等待网络，白白的占用了一个线程等IO。如果业务逻辑层也要消耗很多时间等待网络IO，那么它跟通信层的2-3个数量级的线程数量需求这个特性就被打破了，在极端的业务下，他们甚至重新回来1:1这个比例，举个例子，APP的广告服务，一个请求里可能包含3个广告位，每个广告位从20家广告供应商那里获取广告，再选价格最高的返回给APP展示。这里每一个http请求，需要对外发起60个http请求，按照一个100ms算，需要耗时6秒，如果每秒有1000个广告请求，就需要6000个线程才能不积压至服务崩溃。所以第二代事件驱动模型应运而生，把业务逻辑也变成事件驱动，彻底消除浪费线程等待IO这个现象。事件驱动有两件常见的外衣，一件是异步回调，另一件是coroutine，近几年有了很多应用：Go的goroutinePython 3的coroutineKotlin的coroutinenodejs的异步回调swoole 1的异步回调和swoole 2的coroutineerlang/elixir的process也算是coroutineVertX的异步回调...第二代普遍出现的比较晚，而且只有大厂有这个流量需要用到，所以远没有第一代那么普及，coroutine和csp等概念都是几十年前提出的，流行和普及的晚，因此只能算是老年新生事物。一小搓培训出身的码农，因为基础差底子差，喜欢把这个当作黑科技来吹，所以才变得有些神秘兮兮了。其实它就是一层窗户纸，轻轻捅破，也就这样了，一点儿都不稀奇。真正的门槛和功夫，不是模型本身，是实现这个模型时，处处往死里优化，死抠的那些细节，往往是一般PPT里看不到的。写字人人都会，写出来好不好看，差别就太大了。



Reactor的原理与Python实现
一、原理
二、Python实现Reactor模型
1、首先使用Python实现最基本的网络服务器
	我竟然不知道具体步骤。。。

	服务端的话，是
	首先要创建一个socket，socket是客户端和服务端用来通信的关键，相当于“信箱”
	然后socket要监听一个端口，相当于该服务的"门牌号"
	socket.accept()可以被动接收请求链接，该函数为阻塞的，为了服务更多的请求，将该函数放在死循环内，执行完一个，继续执行下一个。有点像串行
	这里有一点要注意，我以为还是用原来的skt进行操作，但是accept()函数返回了新的socket对象，代表本次连接，具体可看函数定义，所以后续针对连接的操作得用新的
	收到请求后，进行读取数据 new_skt.recv()

	客户端的话，是
	创建一个socket
	进行连接指定的地址,socket.connect(),这里不生成新的socket对象
	往连接内发送数据,socket.send("你好".encode("utf-8"))

	加个sleep，验证这个是单进程(线程)串行阻塞的。性能较差，
	优化一下，让它变成多进程(线程)的模式，
		首先是多进程，先使用os.fork()一个进程去执行任务
		其次使用多线程，使用threading.Thread()
	再优化一下，使用固定数量的线程池

	再优化一下，让它变成异步IO模式
	
	每一步都是加大客户端连接的数量。

2、


从什么点切入学习并发呢？
1、业务场景，有哪些高并发业务场景呢？
	1、抢购，火车票、演唱会门票等等。
	c10k问题
		https://www.jianshu.com/p/ba7fa25d3590


c10k解决方案
1、每个连接单独分配1个进程\线程
	会耗费较多资源，但是改为每个连接单独分配1个协程呢？

2、每个进程/线程处理多个链接

前端可能用的场景比较少，但是也有，比较典型的是下载文件，多线程可以分段同时下载一个文件，比单线程当然快很多。还有就是避免给用户死机的感觉，如果所有业务都在一个主线程中处理，就会让用户感觉到卡，此时多线程可以在完成工作的同时响应用户的交互，提升用户流畅的感觉。

至于后端开发，那就多了，几乎任何一个后端服务都会用到多线程或者协程，都需要并发，简单的说，后端服务是要为前端请求服务的，如果不用多线程、协程、并发这些处理，那就是这样的：当你服务一个客户端请求时，其他请求都处于等待之中，如果这个任务比较重量，你的后端服务就成了单用户的，只能服务一个请求，然后其他请求都在排队等待，最后一个请求就会等前面请求都完成才轮到它，相比多线程，Web后端服务更多的是用协程，因为多核的多线程虽然是并发，但是太重量，切换时间和内存消耗都比较大，而协程很轻，但是协程的缺点是无法充分利用CPU多核的好处，所以，现在最流行的后端框架是单进程+多线程+每个线程再利用协程这样的组合方式，然后多个服务对应多个进程，如此单台服务器可以最大限度充分利用资源，程序写的好的话，一台多核(比如24核)内存大点的(比如64G内存)的现代服务器，可以支持十几万的长连接，可以支撑几百万访问的网站正常运行，这些都得靠多线程、协程、并发这些技术的运用，总之，做后端是完全离不开多线程和并发的。

多进程可以利用多核嘛？

多线程可以利用多核心嘛？
由于线程分用户线程和内核线程。内核线程在调用的时候可以去不同的核心去操作。所以多线程是可以利用到多核的。


《编程语言是如何实现并发的之操作系统篇》

编程语言本质上是调用系统提供的接口来实现基本功能
那么这个并发能力本质上是系统提供的。
系统如何实现并发呢？

灵活使用多进程和多线程和多协程


[IO多路复用是什么意思](https://www.zhihu.com/question/32163005/answer/1802684879)

[为什么事件驱动服务器这么火](https://gist.github.com/jcouyang/9914091)


